{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd97ac78",
   "metadata": {},
   "source": [
    "# Sedona Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5ca60",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568ecd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/26 22:32:35 WARN Utils: Your hostname, cs-spatial-501 resolves to a loopback address: 127.0.0.1; using 128.101.33.153 instead (on interface eno1)\n",
      "25/05/26 22:32:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "https://artifacts.unidata.ucar.edu/repository/unidata-all/ added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /home/uribe055/.ivy2/cache\n",
      "The jars for the packages stored in: /home/uribe055/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-3.5_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      "edu.ucar#cdm-core added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fe87590f-98b7-4ece-8036-ca0788edf2e1;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/uribe055/sedona_experiments/venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.sedona#sedona-spark-3.5_2.12;1.7.1 in central\n",
      "\tfound org.apache.sedona#sedona-common;1.7.1 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound org.locationtech.jts#jts-core;1.20.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.16.1 in central\n",
      "\tfound org.locationtech.spatial4j#spatial4j;0.8 in central\n",
      "\tfound com.google.geometry#s2-geometry;2.0.0 in central\n",
      "\tfound com.google.guava#guava;25.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      "\tfound com.uber#h3;4.1.1 in central\n",
      "\tfound net.sf.geographiclib#GeographicLib-Java;1.52 in central\n",
      "\tfound com.github.ben-manes.caffeine#caffeine;2.9.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.10.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.5.1 in central\n",
      "\tfound org.apache.sedona#sedona-spark-common-3.5_2.12;1.7.1 in central\n",
      "\tfound org.apache.sedona#shade-proto;1.7.1 in central\n",
      "\tfound org.xerial#sqlite-jdbc;3.41.2.2 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound graphframes#graphframes;0.8.3-spark3.5-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central\n",
      "\tfound org.beryx#awt-color-factory;1.0.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.7.1-28.5 in central\n",
      "\tfound edu.ucar#cdm-core;5.4.2 in repo-1\n",
      "\tfound edu.ucar#udunits;5.4.2 in repo-1\n",
      "\tfound edu.ucar#httpservices;5.4.2 in repo-1\n",
      "\tfound com.google.guava#guava;30.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound org.apache.httpcomponents#httpmime;4.5.13 in central\n",
      "\tfound com.google.re2j#re2j;1.3 in central\n",
      "\tfound com.beust#jcommander;1.78 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.12.4 in central\n",
      "\tfound joda-time#joda-time;2.10.3 in central\n",
      "\tfound org.jdom#jdom2;2.0.6 in central\n",
      ":: resolution report :: resolve 7271ms :: artifacts dl 911ms\n",
      "\t:: modules in use:\n",
      "\tcom.beust#jcommander;1.78 from central in [default]\n",
      "\tcom.github.ben-manes.caffeine#caffeine;2.9.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.5.1 from central in [default]\n",
      "\tcom.google.geometry#s2-geometry;2.0.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;30.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.12.4 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.3 from central in [default]\n",
      "\tcom.uber#h3;4.1.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tedu.ucar#cdm-core;5.4.2 from repo-1 in [default]\n",
      "\tedu.ucar#httpservices;5.4.2 from repo-1 in [default]\n",
      "\tedu.ucar#udunits;5.4.2 from repo-1 in [default]\n",
      "\tgraphframes#graphframes;0.8.3-spark3.5-s_2.12 from spark-packages in [default]\n",
      "\tjoda-time#joda-time;2.10.3 from central in [default]\n",
      "\tnet.sf.geographiclib#GeographicLib-Java;1.52 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpmime;4.5.13 from central in [default]\n",
      "\torg.apache.sedona#sedona-common;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-3.5_2.12;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-common-3.5_2.12;1.7.1 from central in [default]\n",
      "\torg.apache.sedona#shade-proto;1.7.1 from central in [default]\n",
      "\torg.beryx#awt-color-factory;1.0.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.7.1-28.5 from central in [default]\n",
      "\torg.jdom#jdom2;2.0.6 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.20.0 from central in [default]\n",
      "\torg.locationtech.spatial4j#spatial4j;0.8 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.16.1 from central in [default]\n",
      "\torg.xerial#sqlite-jdbc;3.41.2.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.guava#guava;25.1-jre by [com.google.guava#guava;30.1-jre] in [default]\n",
      "\torg.checkerframework#checker-qual;2.0.0 by [org.checkerframework#checker-qual;3.10.0] in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 by [com.google.errorprone#error_prone_annotations;2.5.1] in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 by [com.google.j2objc#j2objc-annotations;1.3] in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 transitively in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 by [org.checkerframework#checker-qual;3.10.0] in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.3.4 by [com.google.errorprone#error_prone_annotations;2.5.1] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.28 by [org.slf4j#slf4j-api;1.7.36] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   47  |   0   |   0   |   8   ||   39  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fe87590f-98b7-4ece-8036-ca0788edf2e1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 39 already retrieved (0kB/329ms)\n",
      "25/05/26 22:32:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Start Spark + Sedona\n",
    "config = SedonaContext.builder(). \\\n",
    "    config('spark.jars.repositories', 'https://artifacts.unidata.ucar.edu/repository/unidata-all/'). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-3.5_2.12:1.7.1,'\n",
    "           'org.datasyslab:geotools-wrapper:1.7.1-28.5,'\n",
    "           'edu.ucar:cdm-core:5.4.2'). \\\n",
    "    config('spark.driver.memory', '10g'). \\\n",
    "    config('spark.driver.maxResultSize', '5g'). \\\n",
    "    config('spark.network.timeout', '1000s'). \\\n",
    "    config(\"spark.sql.legacy.parquet.nanosAsLong\", \"true\"). \\\n",
    "    getOrCreate()\n",
    "sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e029bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/26 22:33:01 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf = sedona.read.parquet(f\"/home/uribe055/sedona_experiments/processed_data/*.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d130f7d",
   "metadata": {},
   "source": [
    "Create a geometry column for spatial queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca809108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------------------+--------------+-----------------+\n",
      "|latitude|longitude|               time|2m_temperature|             geom|\n",
      "+--------+---------+-------------------+--------------+-----------------+\n",
      "|    84.0|    -75.0|2023-12-27 00:00:00|     243.76312|   POINT (-75 84)|\n",
      "|    84.0|   -74.75|2023-12-27 00:00:00|     243.75336|POINT (-74.75 84)|\n",
      "|    84.0|    -74.5|2023-12-27 00:00:00|     243.74554| POINT (-74.5 84)|\n",
      "|    84.0|   -74.25|2023-12-27 00:00:00|     243.73773|POINT (-74.25 84)|\n",
      "|    84.0|    -74.0|2023-12-27 00:00:00|     243.72015|   POINT (-74 84)|\n",
      "|    84.0|   -73.75|2023-12-27 00:00:00|     243.66351|POINT (-73.75 84)|\n",
      "|    84.0|    -73.5|2023-12-27 00:00:00|     243.60687| POINT (-73.5 84)|\n",
      "|    84.0|   -73.25|2023-12-27 00:00:00|     243.55023|POINT (-73.25 84)|\n",
      "|    84.0|    -73.0|2023-12-27 00:00:00|     243.49554|   POINT (-73 84)|\n",
      "|    84.0|   -72.75|2023-12-27 00:00:00|      243.4389|POINT (-72.75 84)|\n",
      "|    84.0|    -72.5|2023-12-27 00:00:00|     243.38226| POINT (-72.5 84)|\n",
      "|    84.0|   -72.25|2023-12-27 00:00:00|     243.35883|POINT (-72.25 84)|\n",
      "|    84.0|    -72.0|2023-12-27 00:00:00|     243.33734|   POINT (-72 84)|\n",
      "|    84.0|   -71.75|2023-12-27 00:00:00|      243.3139|POINT (-71.75 84)|\n",
      "|    84.0|    -71.5|2023-12-27 00:00:00|     243.29242| POINT (-71.5 84)|\n",
      "|    84.0|   -71.25|2023-12-27 00:00:00|     243.26898|POINT (-71.25 84)|\n",
      "|    84.0|    -71.0|2023-12-27 00:00:00|      243.2475|   POINT (-71 84)|\n",
      "|    84.0|   -70.75|2023-12-27 00:00:00|     243.22992|POINT (-70.75 84)|\n",
      "|    84.0|    -70.5|2023-12-27 00:00:00|      243.2143| POINT (-70.5 84)|\n",
      "|    84.0|   -70.25|2023-12-27 00:00:00|     243.19867|POINT (-70.25 84)|\n",
      "+--------+---------+-------------------+--------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = sdf.withColumn(\"geom\", expr(\"ST_Point(longitude, latitude)\")).drop(\"number\", \"expver\")\n",
    "sdf.createOrReplaceTempView(\"GL\")\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ab270",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def daily_05(start_time, end_time, min_lat,max_lat,min_lon,max_lon):\n",
    "#     query = f\"\"\"\n",
    "#         SELECT time, int(latitude/0.5)*0.5, int(longitude/0.5)*0.5, avg(2m_temperature)\n",
    "#         FROM GL\n",
    "#         WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "#             AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "#             AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "#         GROUP BY time, int(latitude/0.5), int(longitude/0.5)\n",
    "#         \"\"\"\n",
    "#     return query\n",
    "\n",
    "# def daily_1(start_time, end_time, min_lat,max_lat,min_lon,max_lon):\n",
    "#     query = f\"\"\"\n",
    "#         SELECT time, int(latitude), int(longitude), avg(2m_temperature)\n",
    "#         FROM GL\n",
    "#         WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "#             AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "#             AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "#         GROUP BY time, int(latitude), int(longitude)\n",
    "#         \"\"\"\n",
    "#     return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2465943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily(s, start_time, end_time, min_lat, max_lat, min_lon, max_lon):\n",
    "    q1 = f\"\"\"\n",
    "        FROM GL\n",
    "        WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "            AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "            AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "        \"\"\"\n",
    "    \n",
    "    if s == 0.25:\n",
    "        q0 = f\"\"\"SELECT time, latitude, longitude, avg(2m_temperature)\"\"\" \n",
    "        q2 = \"\"\"GROUP BY time, latitude, longitude\"\"\"\n",
    "    elif s == 0.5:\n",
    "        q0 = f\"\"\"SELECT time, int(latitude/0.5)*0.5, int(longitude/0.5)*0.5, avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY time, int(latitude/0.5), int(longitude/0.5)\"\"\"\n",
    "    else:\n",
    "        q0 = f\"\"\"SELECT time, int(latitude), int(longitude), avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY time, int(latitude), int(longitude)\"\"\"\n",
    "\n",
    "    return q0 + q1 + q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e9546c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly(s, start_time, end_time, min_lat, max_lat, min_lon, max_lon):\n",
    "    q1 = f\"\"\"\n",
    "        FROM GL\n",
    "        WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "            AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "            AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "        \"\"\"\n",
    "    \n",
    "    if s == 0.25:\n",
    "        q0 = f\"\"\"SELECT month(time), latitude, longitude, avg(2m_temperature)\"\"\" \n",
    "        q2 = \"\"\"GROUP BY month(time), latitude, longitude\"\"\"\n",
    "    elif s == 0.5:\n",
    "        q0 = f\"\"\"SELECT month(time), int(latitude/0.5)*0.5, int(longitude/0.5)*0.5, avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY month(time), int(latitude/0.5), int(longitude/0.5)\"\"\"\n",
    "    else:\n",
    "        q0 = f\"\"\"SELECT month(time), int(latitude), int(longitude), avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY month(time), int(latitude), int(longitude)\"\"\"\n",
    "\n",
    "    return q0 + q1 + q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63ddd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly(s, start_time, end_time, min_lat, max_lat, min_lon, max_lon):\n",
    "    q1 = f\"\"\"\n",
    "        FROM GL\n",
    "        WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "            AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "            AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "        \"\"\"\n",
    "    \n",
    "    if s == 0.25:\n",
    "        q0 = f\"\"\"SELECT year(time), latitude, longitude, avg(2m_temperature)\"\"\" \n",
    "        q2 = \"\"\"GROUP BY year(time), latitude, longitude\"\"\"\n",
    "    elif s == 0.5:\n",
    "        q0 = f\"\"\"SELECT year(time), int(latitude/0.5)*0.5, int(longitude/0.5)*0.5, avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY year(time), int(latitude/0.5), int(longitude/0.5)\"\"\"\n",
    "    else:\n",
    "        q0 = f\"\"\"SELECT year(time), int(latitude), int(longitude), avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY year(time), int(latitude), int(longitude)\"\"\"\n",
    "\n",
    "    return q0 + q1 + q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f122a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap_query(s, start_time, end_time, min_lat, max_lat, min_lon, max_lon):\n",
    "    q1 = f\"\"\"\n",
    "        FROM GL\n",
    "        WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "            AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "            AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "        \"\"\"\n",
    "    \n",
    "    if s == 0.25:\n",
    "        q0 = f\"\"\"SELECT latitude, longitude, avg(2m_temperature)\"\"\" \n",
    "        q2 = \"\"\"GROUP BY latitude, longitude\"\"\"\n",
    "    else:   # 1.0\n",
    "        q0 = f\"\"\"SELECT int(latitude), int(longitude), avg(2m_temperature)\"\"\"\n",
    "        q2 = f\"\"\"GROUP BY int(latitude), int(longitude)\"\"\"\n",
    "\n",
    "    return q0 + q1 + q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95e90478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_find_time_query(t, start_time, end_time, min_lat, max_lat, min_lon, max_lon,filter_value):\n",
    "    q1 = f\"\"\"\n",
    "        FROM GL\n",
    "        WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "            AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "            AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "        \"\"\"\n",
    "    if t == \"month\":\n",
    "        q0=f\"\"\"SELECT month(time), avg(2m_temperature)\"\"\"\n",
    "        q2=f\"\"\"GROUP BY month(time)\n",
    "            HAVING avg(2m_temperature) > {filter_value}\n",
    "            \"\"\"\n",
    "    elif t == \"hour\":\n",
    "        q0=f\"\"\"SELECT time, avg(2m_temperature)\"\"\"\n",
    "        q2=f\"\"\"GROUP BY time\n",
    "            HAVING avg(2m_temperature) > {filter_value}\n",
    "            \"\"\"\n",
    "    else:   # t == \"year\"\n",
    "        q0=f\"\"\"SELECT year(time), avg(2m_temperature)\"\"\"\n",
    "        q2=f\"\"\"GROUP BY year(time)\n",
    "            HAVING avg(2m_temperature) > {filter_value}\n",
    "            \"\"\"\n",
    "\n",
    "    return q0 + q1 + q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bae6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sedona.sql(yearly(1.0, \"2020-01-01 00:00:00\",\"2024-12-31 23:00:00\",60,85,-69,-10,))\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e71f79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a57bcc",
   "metadata": {},
   "source": [
    "### Changing Spatial and Temporal Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bce570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "t_res = [\"hour\",\"hour\",\"hour\", \"day\",\"day\",\"day\", \"year\",\"year\",\"year\", \"month\",\"month\"]\n",
    "s_res = [0.25, 0.5, 1.0, 0.25, 0.5, 1.0, 0.25, 0.5, 1.0, 0.5, 1.0]\n",
    "\n",
    "start_time = \"2020-01-01 00:00:00\"\n",
    "end_time = \"2024-12-31 23:00:00\"\n",
    "min_lat = 60\n",
    "max_lat = 80\n",
    "min_lon = -60\n",
    "max_lon = -30\n",
    "outfilename = \"/home/uribe055/sedona_experiments/results_\" + \"changing_resolution.csv\"\n",
    "\n",
    "results_list = []\n",
    "for t, s in zip(t_res, s_res):\n",
    "    if t == \"hour\":\n",
    "        query = f\"\"\"SELECT time, latitude, longitude, avg(2m_temperature)\n",
    "                FROM GL\n",
    "                WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "                    AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "                    AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "                GROUP BY time, latitude, longitude\n",
    "                \"\"\"\n",
    "    elif t == \"day\":\n",
    "        query = daily(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "    elif t == \"month\":\n",
    "        query = monthly(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "    else:\n",
    "        query = yearly(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "\n",
    "    query_start = time.time()\n",
    "    result = sedona.sql(query)\n",
    "    result.collect()\n",
    "    query_end = time.time()\n",
    "\n",
    "    results_list.append({\"sys\": \"Sedona\", \n",
    "                         \"t_res\": t,\n",
    "                         \"s_res\": s,\n",
    "                         \"time_span\":5,             # FOR HEATMAP\n",
    "                         \"tr\": None,\n",
    "                         \"ta\": None,\n",
    "                         \"total_time\": query_end - query_start,\n",
    "                         \"percent_area\":100     # FOR CHANGING RESULT SIZE\n",
    "                        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "out_file = os.path.join(outfilename)\n",
    "results_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f1074",
   "metadata": {},
   "source": [
    "### Changing Result Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4833e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# res_pairs = [(\"hour\", 0.25), (\"year\", 0.25), (\"month\", 0.5), (\"hour\", 1.0), (\"year\", 1.0)]\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "start_time = \"2020-01-01 00:00:00\"\n",
    "end_time = \"2024-12-31 23:00:00\"\n",
    "t_res = [\"hour\", \"year\", \"month\", \"hour\", \"year\"]\n",
    "s_res = [0.25, 0.25, 0.5, 1.0, 1.0]\n",
    "\n",
    "coord_dict = {\"1\": [83,86,-20,-15],\n",
    "              \"25\": [65,80,-55,-30],\n",
    "              \"50\": [60,85,-60,-30]\n",
    "}\n",
    "percent_area = [1, 25, 50]\n",
    "outfilename = \"/home/uribe055/sedona_experiments/results_\" + \"changing_result_size.csv\"\n",
    "\n",
    "results_list = []\n",
    "for t, s in zip(t_res, s_res):\n",
    "    for pa in percent_area:\n",
    "        coords = coord_dict[str(pa)]\n",
    "        min_lat = coords[0]\n",
    "        max_lat = coords[1]\n",
    "        min_lon = coords[2]\n",
    "        max_lon = coords[3]\n",
    "        if t == \"hour\":\n",
    "            query = f\"\"\"SELECT time, latitude, longitude, avg(2m_temperature)\n",
    "                    FROM GL\n",
    "                    WHERE latitude BETWEEN {min_lat} AND {max_lat}\n",
    "                        AND longitude BETWEEN {min_lon} AND {max_lon}\n",
    "                        AND time BETWEEN '{start_time}' AND '{end_time}'\n",
    "                    GROUP BY time, latitude, longitude\n",
    "                    \"\"\"\n",
    "        elif t == \"day\":\n",
    "            query = daily(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "        elif t == \"month\":\n",
    "            query = monthly(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "        else:\n",
    "            query = yearly(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "\n",
    "        query_start = time.time()\n",
    "        result = sedona.sql(query)\n",
    "        result.collect()\n",
    "        query_end = time.time()\n",
    "\n",
    "        results_list.append({\"sys\": \"Sedona\", \n",
    "                            \"t_res\": t,\n",
    "                            \"s_res\": s,\n",
    "                            \"time_span\":5,             # FOR HEATMAP\n",
    "                            \"tr\": None,\n",
    "                            \"ta\": None,\n",
    "                            \"total_time\": query_end - query_start,\n",
    "                            \"percent_area\":pa     # FOR CHANGING RESULT SIZE\n",
    "                            })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "out_file = os.path.join(outfilename)\n",
    "results_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5071d0",
   "metadata": {},
   "source": [
    "### Heatmap Query Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0cc28",
   "metadata": {},
   "source": [
    "Ran three times to get better average of 2.5 year timespan point execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2951316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# [\"025_H\", \"025_Y\", \"05_M\", \"1_H\", \"1_Y\"]\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "num_years_dict = {\"1\": [\"2017-01-01 00:00:00\", \"2017-12-31 23:00:00\"],\n",
    "                  \"2.5\": [\"2019-01-01 00:00:00\", \"2021-06-31 23:00:00\"],\n",
    "                  \"5\": [\"2020-01-01 00:00:00\", \"2024-12-31 23:00:00\"],\n",
    "                  \"10\": [\"2015-01-01 00:00:00\", \"2024-12-31 23:00:00\"]\n",
    "}\n",
    "time_span = [1, 2.5, 5, 10]\n",
    "# t_res = [\"year\", \"year\"]\n",
    "s_res = [0.25, 1.0]\n",
    "min_lat = 60\n",
    "max_lat = 80\n",
    "min_lon = -60\n",
    "max_lon = -30\n",
    "outfilename = \"/home/uribe055/sedona_experiments/results/results_heatmap_10yrs.csv\"\n",
    "\n",
    "results_list = []\n",
    "for s in s_res:\n",
    "    for num_yrs in time_span:\n",
    "        timestamps = num_years_dict[str(num_yrs)]\n",
    "        start_time = timestamps[0]\n",
    "        end_time = timestamps[1]\n",
    "\n",
    "        query = get_heatmap_query(s, start_time,end_time,min_lat,max_lat,min_lon,max_lon)\n",
    "\n",
    "        query_start = time.time()\n",
    "        result = sedona.sql(query)\n",
    "        result.collect()\n",
    "        query_end = time.time()\n",
    "\n",
    "        results_list.append({\"sys\": \"Sedona\", \n",
    "                            \"t_res\": \"year\",\n",
    "                            \"s_res\": s,\n",
    "                            \"time_span\":num_yrs,             # FOR HEATMAP\n",
    "                            \"tr\": None,\n",
    "                            \"ta\": None,\n",
    "                            \"total_time\": query_end - query_start,\n",
    "                            \"percent_area\":100    # FOR CHANGING RESULT SIZE\n",
    "                            })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "out_file = os.path.join(outfilename)\n",
    "results_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d572ae8",
   "metadata": {},
   "source": [
    "### Find Time Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b471a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "start_time = \"2020-01-01 00:00:00\"\n",
    "end_time = \"2024-12-31 23:00:00\"\n",
    "t_res = [\"hour\", \"month\", \"year\"]\n",
    "s_res = [1, 0.5, 1]\n",
    "filter_values = [205, 240, 275, 310]\n",
    "min_lat = 60\n",
    "max_lat = 80\n",
    "min_lon = -60\n",
    "max_lon = -30\n",
    "outfilename = \"/home/uribe055/sedona_experiments/results_find_time.csv\"\n",
    "\n",
    "results_list = []\n",
    "for t, s in zip(t_res, s_res):\n",
    "    for val in filter_values:\n",
    "\n",
    "        query = get_find_time_query(t, start_time,end_time,min_lat,max_lat,min_lon,max_lon,val)\n",
    "\n",
    "        query_start = time.time()\n",
    "        result = sedona.sql(query)\n",
    "        result.collect()\n",
    "        query_end = time.time()\n",
    "\n",
    "        results_list.append({\"sys\": \"Sedona\", \n",
    "                            \"t_res\": t,\n",
    "                            \"s_res\": s,\n",
    "                            \"time_span\":5,             # FOR HEATMAP\n",
    "                            \"tr\": None,\n",
    "                            \"ta\": None,\n",
    "                            \"total_time\": query_end - query_start,\n",
    "                            \"percent_area\":100,    # FOR CHANGING RESULT SIZE\n",
    "                            \"filter_value\":val\n",
    "                            })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "out_file = os.path.join(outfilename)\n",
    "results_df.to_csv(out_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
